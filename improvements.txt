Siguientes pasos:
    - Con los resultados de optuna, coger el que menor value tenga (para davies) o mayor para silhouette_coefficients
    - Con esos hacer un experimento simple y representar el plot, coger los knn más cercanos, etc. 
    - Y guardar todo eso. No almacenar fechas ni nada. Solo nombre del algoritmo y resultados con optuna. 
    - Con las tres imágenes de cada centroide, que salgan en pantalla con el cluster arriba. 



TOP DOWN - No hay implementación en sklearn.
Podríamos hacerle a mano si hiciera falta. 



Rutas de directorios con los resultados.
    - Cada tipo de cluster debe tener su árbol de rutas en función de las métricas que vamos a utilizar
    - El tema es que no es muy estándar para cada cluster. Por ello hay que verlo uno por uno y no se puede automatizar como tal.
    - f"metric_{metric}/min_cluster_size_{min_cluster_size}/n_clusters_{n_clusters}/plot.png"
        Viene determinada por la métrica, y demás hiperparámetros, pero n_clusters es calculado. 
    - f"metric_{metric}/min_cluster_size_{min_cluster_size}/n_clusters_{n_clusters}/knn_points/points.csv"
    En fin. Que se podría refactorizar un poco sí, cuando tenga más tiempo.


score_silhouette = silhouette_score(self.data, kmeans.labels_)
score_davies = davies_bouldin_score(self.data, kmeans.labels_)
silhouette_coefficients.append(score_silhouette)
davies_bouldin_coefficients.append(score_davies)
k_.append(k)

    Esto se repite en todas las clases de los clusters
    

